"""
Tissue Segmentation Module

Advanced tissue separation and segmentation for multi-tissue iQID raw images.
Migrated and refactored from legacy process_object.py and adaptive_segmentation.py.

This module implements the TissueSeparator class for automated tissue separation
from raw multi-tissue iQID images, with validation against ground truth data.
"""

import numpy as np
import cv2
import os
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Union, Any
import logging
from datetime import datetime
import glob

# Image processing imports
try:
    from skimage import filters, morphology, measure, segmentation, feature
    from skimage.morphology import disk, opening, closing
    from scipy import ndimage
    from scipy.spatial.distance import pdist, squareform
    from scipy.cluster.hierarchy import linkage, fcluster
    HAS_SKIMAGE = True
except ImportError:
    HAS_SKIMAGE = False
    
try:
    from sklearn.cluster import DBSCAN, MeanShift
    HAS_SKLEARN = True
except ImportError:
    HAS_SKLEARN = False

# Internal imports
from ..utils.io_utils import natural_sort, find_files_with_pattern, ensure_directory_exists
from ..utils.math_utils import normalize_array, calculate_statistics


class TissueSeparator:
    """
    Advanced tissue separation from multi-tissue raw iQID images.
    
    This class implements sophisticated segmentation algorithms to automatically
    separate multi-tissue raw iQID images into individual tissue types
    (e.g., kidney left/right, tumor, etc.).
    
    Key Features:
    - Adaptive clustering for low-contrast images
    - Multi-threshold segmentation
    - Noise-robust blob detection
    - Ground truth validation
    - Comprehensive quality metrics (IoU, Dice, precision, recall)
    """
    
    def __init__(self, 
                 method: str = 'adaptive_clustering',
                 min_blob_area: int = 50,
                 max_blob_area: int = 50000,
                 preserve_blobs: bool = True,
                 use_clustering: bool = True):
        """
        Initialize the tissue separator.
        
        Parameters
        ----------
        method : str, default 'adaptive_clustering'
            Segmentation method to use:
            - 'adaptive_clustering': Cluster distributed dots into tissue blobs
            - 'multi_threshold': Multiple threshold levels
            - 'watershed': Watershed-based segmentation
            - 'combined': Combination of multiple methods
        min_blob_area : int, default 50
            Minimum area for valid tissue blobs (pixels)
        max_blob_area : int, default 50000
            Maximum area for valid tissue blobs (pixels)
        preserve_blobs : bool, default True
            If True, use less aggressive morphological operations
        use_clustering : bool, default True
            If True, use clustering to group distributed dots
        """
        self.method = method
        self.min_blob_area = min_blob_area
        self.max_blob_area = max_blob_area
        self.preserve_blobs = preserve_blobs
        self.use_clustering = use_clustering
        
        # Initialize logging
        self.logger = logging.getLogger(__name__)
        
        # Validation data structures
        self._validation_results = {}
        self._processing_stats = {}
        
        # Check for required dependencies
        if not HAS_SKIMAGE:
            raise ImportError(
                "scikit-image is required for tissue segmentation. "
                "Install with: pip install scikit-image"
            )
    
    def separate_tissues(self, 
                        raw_image_path: Union[str, Path], 
                        output_dir: Optional[Union[str, Path]] = None) -> Dict[str, List[Path]]:
        """
        Separate tissues from a raw multi-tissue iQID image.
        
        This is the main public method that processes a raw image and returns
        separated tissue images, each containing a single tissue type.
        
        Parameters
        ----------
        raw_image_path : str or Path
            Path to the raw multi-tissue iQID image file
        output_dir : str or Path, optional
            Directory to save separated tissue images. If None, creates
            a subdirectory next to the input file.
            
        Returns
        -------
        Dict[str, List[Path]]
            Dictionary mapping tissue type names to lists of image file paths:
            {
                'kidney_left': [path1, path2, ...],
                'kidney_right': [path3, path4, ...], 
                'tumor': [path5, path6, ...],
                ...
            }
        """
        raw_image_path = Path(raw_image_path)
        
        if not raw_image_path.exists():
            raise FileNotFoundError(f"Raw image file not found: {raw_image_path}")
        
        self.logger.info(f"Starting tissue separation for: {raw_image_path}")
        
        # Set up output directory
        if output_dir is None:
            output_dir = raw_image_path.parent / f"{raw_image_path.stem}_separated"
        else:
            output_dir = Path(output_dir)
        
        ensure_directory_exists(output_dir)
        
        # Load and preprocess the raw image
        raw_image = self._load_raw_image(raw_image_path)
        preprocessed_image = self._preprocess_raw_image(raw_image)
        
        # Detect tissue regions
        tissue_regions = self._detect_tissue_regions(preprocessed_image)
        
        # Classify tissues by type
        classified_tissues = self._classify_tissue_types(tissue_regions, preprocessed_image)
        
        # Generate separated tissue images
        separated_paths = self._generate_separated_images(
            classified_tissues, preprocessed_image, output_dir, raw_image_path.stem
        )
        
        # Store processing statistics
        self._processing_stats[str(raw_image_path)] = {
            'num_regions_detected': len(tissue_regions),
            'num_tissues_classified': len(classified_tissues),
            'tissue_types': list(classified_tissues.keys()),
            'output_dir': str(output_dir)
        }
        
        self.logger.info(f"Tissue separation complete. Found {len(classified_tissues)} tissue types.")
        
        return separated_paths
    
    def validate_against_ground_truth(self, 
                                    automated_results: Dict[str, List[Path]], 
                                    ground_truth_dirs: Dict[str, Path]) -> Dict[str, Any]:
        """
        Validate automated tissue separation against ground truth data.
        
        Parameters
        ----------
        automated_results : Dict[str, List[Path]]
            Results from separate_tissues() method
        ground_truth_dirs : Dict[str, Path]
            Dictionary mapping tissue types to ground truth directory paths:
            {'kidney_left': Path('gt/kidney_left/'), ...}
            
        Returns
        -------
        Dict[str, Any]
            Validation results with metrics for each tissue type:
            {
                'overall': {'avg_iou': float, 'avg_dice': float, ...},
                'by_tissue': {
                    'kidney_left': {'iou': float, 'dice': float, ...},
                    'kidney_right': {'iou': float, 'dice': float, ...},
                    ...
                }
            }
        """
        self.logger.info("Starting ground truth validation")
        
        validation_results = {
            'overall': {},
            'by_tissue': {},
            'detailed': {}
        }
        
        all_ious = []
        all_dices = []
        all_precisions = []
        all_recalls = []
        
        for tissue_type, automated_paths in automated_results.items():
            if tissue_type not in ground_truth_dirs:
                self.logger.warning(f"No ground truth available for tissue type: {tissue_type}")
                continue
            
            gt_dir = Path(ground_truth_dirs[tissue_type])
            if not gt_dir.exists():
                self.logger.warning(f"Ground truth directory not found: {gt_dir}")
                continue
            
            # Compare automated results with ground truth
            tissue_metrics = self._compare_tissue_with_ground_truth(
                automated_paths, gt_dir, tissue_type
            )
            
            validation_results['by_tissue'][tissue_type] = tissue_metrics
            
            # Collect overall metrics
            if 'iou' in tissue_metrics:
                all_ious.append(tissue_metrics['iou'])
            if 'dice' in tissue_metrics:
                all_dices.append(tissue_metrics['dice'])
            if 'precision' in tissue_metrics:
                all_precisions.append(tissue_metrics['precision'])
            if 'recall' in tissue_metrics:
                all_recalls.append(tissue_metrics['recall'])
        
        # Calculate overall metrics
        if all_ious:
            validation_results['overall']['avg_iou'] = np.mean(all_ious)
            validation_results['overall']['std_iou'] = np.std(all_ious)
        if all_dices:
            validation_results['overall']['avg_dice'] = np.mean(all_dices)
            validation_results['overall']['std_dice'] = np.std(all_dices)
        if all_precisions:
            validation_results['overall']['avg_precision'] = np.mean(all_precisions)
        if all_recalls:
            validation_results['overall']['avg_recall'] = np.mean(all_recalls)
        
        # Store validation results
        self._validation_results.update(validation_results)
        
        self.logger.info(f"Validation complete. Overall IoU: {validation_results['overall'].get('avg_iou', 'N/A'):.3f}")
        
        return validation_results
    
    def calculate_segmentation_metrics(self, 
                                     predicted_mask: np.ndarray, 
                                     ground_truth_mask: np.ndarray) -> Dict[str, float]:
        """
        Calculate comprehensive segmentation quality metrics.
        
        Parameters
        ----------
        predicted_mask : np.ndarray
            Binary mask from automated segmentation
        ground_truth_mask : np.ndarray
            Binary ground truth mask
            
        Returns
        -------
        Dict[str, float]
            Dictionary with segmentation metrics:
            - 'iou': Intersection over Union (Jaccard index)
            - 'dice': Dice coefficient (F1 score)
            - 'precision': Precision score
            - 'recall': Recall score (sensitivity)
            - 'specificity': Specificity score
            - 'accuracy': Overall accuracy
        """
        # Ensure binary masks
        pred_binary = (predicted_mask > 0).astype(bool)
        gt_binary = (ground_truth_mask > 0).astype(bool)
        
        # Calculate intersection and union
        intersection = np.logical_and(pred_binary, gt_binary).sum()
        union = np.logical_or(pred_binary, gt_binary).sum()
        
        # True/False positives/negatives
        tp = intersection  # True positives
        fp = pred_binary.sum() - tp  # False positives
        fn = gt_binary.sum() - tp  # False negatives
        tn = (~pred_binary & ~gt_binary).sum()  # True negatives
        
        # Calculate metrics with safe division
        metrics = {}
        
        # IoU (Intersection over Union)
        metrics['iou'] = intersection / union if union > 0 else 0.0
        
        # Dice coefficient (F1 score)
        metrics['dice'] = (2 * intersection) / (pred_binary.sum() + gt_binary.sum()) if (pred_binary.sum() + gt_binary.sum()) > 0 else 0.0
        
        # Precision
        metrics['precision'] = tp / (tp + fp) if (tp + fp) > 0 else 0.0
        
        # Recall (Sensitivity)
        metrics['recall'] = tp / (tp + fn) if (tp + fn) > 0 else 0.0
        
        # Specificity
        metrics['specificity'] = tn / (tn + fp) if (tn + fp) > 0 else 0.0
        
        # Accuracy
        metrics['accuracy'] = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0.0
        
        return metrics
    
    # Private methods for internal processing
    
    def _load_raw_image(self, image_path: Path) -> np.ndarray:
        """
        Load raw iQID image data.
        
        Migrated from legacy process_object.py load methods.
        """
        try:
            if image_path.suffix.lower() in ['.dat', '.raw']:
                # Handle binary iQID format (migrated from ClusterData.load_cluster_data)
                return self._load_iqid_binary_data(image_path)
            else:
                # Handle standard image formats
                from skimage import io
                return io.imread(str(image_path))
        except Exception as e:
            self.logger.error(f"Failed to load image {image_path}: {e}")
            raise
    
    def _load_iqid_binary_data(self, file_path: Path) -> np.ndarray:
        """
        Load binary iQID data format.
        
        Migrated from ClusterData.load_cluster_data() and init_header().
        """
        # Read header to get dimensions
        header = np.fromfile(str(file_path), dtype=np.int32, count=100)
        header_size = header[0]
        xdim = header[1]
        ydim = header[2]
        
        file_size_bytes = os.path.getsize(str(file_path))
        
        # Determine data type and number of elements based on file structure
        # For processed listmode data
        num_data_elements = 14  # Default for processed_lm format
        
        byte_size = 8  # Using float64
        byte_fac = 2
        
        num_clusters = np.floor(
            (file_size_bytes - 4 * header_size) / (byte_size * num_data_elements))
        
        # Load the data
        unshaped_data = np.fromfile(
            str(file_path), 
            dtype=np.float64, 
            count=header_size // byte_fac + int(num_clusters * num_data_elements)
        )
        
        data = unshaped_data[header_size // byte_fac:].reshape(
            int(num_data_elements), int(num_clusters), order='F'
        )
        
        # Extract coordinate data (migrated from init_metadata)
        yC_global = data[4, :]  # Y coordinates
        xC_global = data[5, :]  # X coordinates
        cluster_area = data[3, :]  # Cluster areas
        sum_cluster_signal = data[2, :]  # Signal intensities
        
        # Create 2D image from coordinate data
        image = np.zeros((ydim, xdim), dtype=np.float64)
        
        # Populate image with cluster data
        for i in range(len(xC_global)):
            x_coord = int(np.clip(xC_global[i], 0, xdim - 1))
            y_coord = int(np.clip(yC_global[i], 0, ydim - 1))
            
            # Use signal intensity if available, otherwise use area
            intensity = sum_cluster_signal[i] if len(sum_cluster_signal) > i else cluster_area[i]
            image[y_coord, x_coord] = intensity
        
        return image
    
    def _preprocess_raw_image(self, raw_image: np.ndarray) -> np.ndarray:
        """
        Preprocess raw image for segmentation.
        
        Applies noise reduction, normalization, and enhancement.
        """
        # Normalize the image
        preprocessed = normalize_array(raw_image, method='minmax')
        
        # Apply gentle smoothing to reduce noise while preserving edges
        if HAS_SKIMAGE:
            preprocessed = filters.gaussian(preprocessed, sigma=1.0, preserve_range=True)
        
        return preprocessed
    
    def _detect_tissue_regions(self, image: np.ndarray) -> List[Dict[str, Any]]:
        """
        Detect tissue regions using the specified segmentation method.
        
        Migrated and enhanced from adaptive_segmentation.py
        """
        if self.method == 'adaptive_clustering':
            return self._clustering_based_segmentation(image)
        elif self.method == 'multi_threshold':
            return self._multi_threshold_segmentation(image)
        elif self.method == 'watershed':
            return self._watershed_segmentation(image)
        elif self.method == 'combined':
            return self._combined_segmentation(image)
        else:
            self.logger.warning(f"Unknown method {self.method}, using adaptive_clustering")
            return self._clustering_based_segmentation(image)
    
    def _clustering_based_segmentation(self, image: np.ndarray) -> List[Dict[str, Any]]:
        """
        Use clustering to group distributed dots into tissue blobs.
        
        Migrated from adaptive_segmentation.py
        """
        self.logger.debug("Running clustering-based segmentation")
        
        # Detect individual activity dots
        dot_positions = self._detect_activity_dots(image)
        
        if len(dot_positions) < 2:
            self.logger.debug("Not enough dots for clustering, using threshold fallback")
            return self._fallback_threshold_segmentation(image)
        
        # Cluster dots into tissue groups
        tissue_clusters = self._cluster_dots_into_tissues(dot_positions, image)
        
        # Create tissue regions from clusters
        regions = self._create_regions_from_clusters(image, tissue_clusters, dot_positions)
        
        self.logger.debug(f"Detected {len(regions)} tissue regions from {len(dot_positions)} dots")
        return regions
    
    def _detect_activity_dots(self, image: np.ndarray) -> np.ndarray:
        """
        Detect individual activity dots/peaks in the image.
        
        Enhanced implementation migrated from adaptive_segmentation.py
        Uses multiple approaches to detect weak signals.
        """
        # Method 1: Local maxima detection with adaptive thresholds
        if HAS_SKIMAGE:
            # Calculate adaptive threshold
            non_zero_values = image[image > 0]
            if len(non_zero_values) > 0:
                threshold_abs = np.percentile(non_zero_values, 15)
            else:
                threshold_abs = 0
            
            local_maxima = feature.peak_local_max(
                image,
                min_distance=3,
                threshold_abs=threshold_abs,
                threshold_rel=0.1
            )
            
            dots_maxima = np.column_stack(local_maxima) if len(local_maxima[0]) > 0 else np.array([]).reshape(0, 2)
        else:
            dots_maxima = np.array([]).reshape(0, 2)
        
        # Method 2: Connected components on low threshold
        non_zero_values = image[image > 0]
        if len(non_zero_values) > 0:
            low_threshold = np.percentile(non_zero_values, 25)
        else:
            low_threshold = 0
            
        binary_low = image > low_threshold
        
        # Minimal noise removal to preserve blob structure
        if self.preserve_blobs:
            kernel_spike = np.ones((2, 2), np.uint8)
            binary_cleaned = cv2.morphologyEx(binary_low.astype(np.uint8), cv2.MORPH_OPEN, kernel_spike)
        else:
            # More aggressive noise removal
            kernel = np.ones((3, 3), np.uint8)
            binary_cleaned = cv2.morphologyEx(binary_low.astype(np.uint8), cv2.MORPH_OPEN, kernel)
        
        # Find centroids of small connected components (individual dots)
        if HAS_SKIMAGE:
            labeled = measure.label(binary_cleaned)
            dots_cc = []
            
            for region in measure.regionprops(labeled):
                if 1 <= region.area <= 50:  # Individual dots should be small
                    dots_cc.append(region.centroid)
            
            dots_cc = np.array(dots_cc) if dots_cc else np.array([]).reshape(0, 2)
        else:
            dots_cc = np.array([]).reshape(0, 2)
        
        # Method 3: Additional peak detection using gradient-based approach
        if HAS_SKIMAGE:
            # Use gradient magnitude to find edges/peaks
            grad_magnitude = np.sqrt(
                filters.sobel_h(image)**2 + filters.sobel_v(image)**2
            )
            
            # Find peaks in gradient magnitude
            grad_threshold = np.percentile(grad_magnitude[grad_magnitude > 0], 90) if np.any(grad_magnitude > 0) else 0
            grad_peaks = feature.peak_local_max(
                grad_magnitude,
                min_distance=2,
                threshold_abs=grad_threshold * 0.5
            )
            
            dots_gradient = np.column_stack(grad_peaks) if len(grad_peaks[0]) > 0 else np.array([]).reshape(0, 2)
        else:
            dots_gradient = np.array([]).reshape(0, 2)
        
        # Combine all detection methods
        all_dots_list = []
        for dots in [dots_maxima, dots_cc, dots_gradient]:
            if len(dots) > 0:
                all_dots_list.append(dots)
        
        if all_dots_list:
            all_dots = np.vstack(all_dots_list)
            
            # Remove duplicate detections (dots within 2 pixels of each other)
            if len(all_dots) > 1:
                from scipy.spatial.distance import pdist, squareform
                distances = squareform(pdist(all_dots))
                np.fill_diagonal(distances, np.inf)  # Ignore self-distances
                
                # Find duplicates
                duplicate_mask = np.zeros(len(all_dots), dtype=bool)
                for i in range(len(all_dots)):
                    if duplicate_mask[i]:
                        continue
                    close_points = np.where(distances[i] < 2.0)[0]
                    if len(close_points) > 0:
                        # Keep the first point, mark others as duplicates
                        duplicate_mask[close_points] = True
                
                all_dots = all_dots[~duplicate_mask]
        else:
            all_dots = np.array([]).reshape(0, 2)
        
        self.logger.debug(f"Detected {len(all_dots)} activity dots using combined methods")
        return all_dots
    
    def _cluster_dots_into_tissues(self, dot_positions: np.ndarray, image: np.ndarray) -> List[List[int]]:
        """
        Cluster nearby dots into tissue groups using multiple clustering methods.
        
        Enhanced implementation with adaptive clustering approach.
        """
        if len(dot_positions) < 2:
            return []
        
        self.logger.debug(f"Clustering {len(dot_positions)} dots into tissue groups")
        
        # Method 1: Hierarchical clustering (primary method)
        try:
            distances = pdist(dot_positions)
            if len(distances) == 0:
                return [list(range(len(dot_positions)))]
                
            linkage_matrix = linkage(distances, method='ward')
            
            # Adaptive cluster count based on image characteristics
            image_area = image.shape[0] * image.shape[1]
            dot_density = len(dot_positions) / image_area
            
            # Estimate number of tissues based on dot distribution
            if dot_density > 0.001:  # High density - likely more tissues
                max_clusters = min(6, max(2, len(dot_positions) // 5))
            else:  # Lower density - fewer tissues
                max_clusters = min(4, max(2, len(dot_positions) // 8))
            
            if max_clusters < 2:
                return [list(range(len(dot_positions)))]
            
            cluster_labels = fcluster(linkage_matrix, max_clusters, criterion='maxclust')
            
            # Group dot indices by cluster
            clusters = []
            for cluster_id in range(1, max_clusters + 1):
                cluster_dots = [i for i, label in enumerate(cluster_labels) if label == cluster_id]
                if len(cluster_dots) >= 2:  # Only keep clusters with multiple dots
                    clusters.append(cluster_dots)
            
            if clusters:
                self.logger.debug(f"Hierarchical clustering found {len(clusters)} tissue clusters")
                return clusters
            
        except Exception as e:
            self.logger.warning(f"Hierarchical clustering failed: {e}")
        
        # Method 2: DBSCAN clustering (fallback)
        if HAS_SKLEARN and self.use_clustering:
            try:
                # Adaptive epsilon based on image size
                eps = max(10, min(50, np.sqrt(image.shape[0] * image.shape[1]) / 20))
                min_samples = max(2, len(dot_positions) // 10)
                
                dbscan = DBSCAN(eps=eps, min_samples=min_samples)
                cluster_labels = dbscan.fit_predict(dot_positions)
                
                # Group dots by cluster (ignore noise points labeled as -1)
                clusters = []
                unique_labels = set(cluster_labels) - {-1}
                
                for label in unique_labels:
                    cluster_dots = [i for i, l in enumerate(cluster_labels) if l == label]
                    if len(cluster_dots) >= 2:
                        clusters.append(cluster_dots)
                
                if clusters:
                    self.logger.debug(f"DBSCAN clustering found {len(clusters)} tissue clusters")
                    return clusters
                    
            except Exception as e:
                self.logger.warning(f"DBSCAN clustering failed: {e}")
        
        # Method 3: Distance-based grouping (final fallback)
        return self._simple_distance_clustering(dot_positions, image)
    
    def _simple_distance_clustering(self, dot_positions: np.ndarray, image: np.ndarray) -> List[List[int]]:
        """
        Simple distance-based clustering as a fallback method.
        """
        if len(dot_positions) < 2:
            return [list(range(len(dot_positions)))]
        
        # Use simple distance threshold
        distance_threshold = max(20, min(100, np.sqrt(image.shape[0] * image.shape[1]) / 15))
        
        clusters = []
        unassigned = list(range(len(dot_positions)))
        
        while unassigned:
            # Start new cluster with first unassigned point
            current_cluster = [unassigned.pop(0)]
            
            # Find all points within distance threshold
            changed = True
            while changed:
                changed = False
                for i in list(unassigned):
                    # Check distance to any point in current cluster
                    min_dist = min([
                        np.linalg.norm(dot_positions[i] - dot_positions[j])
                        for j in current_cluster
                    ])
                    
                    if min_dist <= distance_threshold:
                        current_cluster.append(i)
                        unassigned.remove(i)
                        changed = True
            
            if len(current_cluster) >= 2:  # Only keep clusters with multiple dots
                clusters.append(current_cluster)
        
        self.logger.debug(f"Distance-based clustering found {len(clusters)} tissue clusters")
        return clusters
    
    def _create_regions_from_clusters(self, image: np.ndarray, clusters: List[List[int]], dot_positions: np.ndarray) -> List[Dict[str, Any]]:
        """
        Create tissue region descriptors from dot clusters.
        """
        regions = []
        
        for i, cluster_indices in enumerate(clusters):
            if not cluster_indices:
                continue
            
            cluster_dots = dot_positions[cluster_indices]
            
            # Calculate cluster properties
            centroid = np.mean(cluster_dots, axis=0)
            
            # Create bounding box around cluster
            min_row, min_col = np.min(cluster_dots, axis=0)
            max_row, max_col = np.max(cluster_dots, axis=0)
            
            # Expand bounding box slightly
            padding = 10
            bbox = (
                max(0, int(min_row - padding)),
                max(0, int(min_col - padding)),
                min(image.shape[0], int(max_row + padding)),
                min(image.shape[1], int(max_col + padding))
            )
            
            # Extract region from image
            region_image = image[bbox[0]:bbox[2], bbox[1]:bbox[3]]
            
            # Estimate area based on cluster size and local image intensity
            estimated_area = len(cluster_indices) * 10  # Rough estimate
            
            region_info = {
                'cluster_id': i,
                'centroid': centroid,
                'bbox': bbox,
                'area': estimated_area,
                'dot_count': len(cluster_indices),
                'dot_positions': cluster_dots,
                'region_image': region_image
            }
            
            regions.append(region_info)
        
        return regions
    
    def _multi_threshold_segmentation(self, image: np.ndarray, num_thresholds: int = 3) -> np.ndarray:
        """
        Apply multi-level thresholding for tissue separation.
        
        Args:
            image: Input grayscale image
            num_thresholds: Number of threshold levels
            
        Returns:
            Multi-level segmented image
        """
        try:
            # Apply Gaussian filter to reduce noise
            filtered = filters.gaussian(image, sigma=1.0)
            
            # Use Otsu's method with multiple thresholds
            thresholds = filters.threshold_multiotsu(filtered, classes=num_thresholds + 1)
            
            # Create multi-level segmentation
            segmented = np.digitize(filtered, thresholds)
            
            return segmented.astype(np.uint8)
            
        except Exception as e:
            self.logger.error(f"Multi-threshold segmentation failed: {e}")
            # Fallback to simple binary threshold
            threshold = filters.threshold_otsu(image)
            return (image > threshold).astype(np.uint8)
    
    def _watershed_segmentation(self, image: np.ndarray, markers: Optional[np.ndarray] = None) -> np.ndarray:
        """
        Apply watershed segmentation for tissue separation.
        
        Args:
            image: Input grayscale image
            markers: Optional marker image for seeded watershed
            
        Returns:
            Watershed segmented image
        """
        try:
            # Compute gradient magnitude
            gradient = filters.sobel(image)
            
            if markers is None:
                # Auto-generate markers using local maxima
                local_maxima = feature.peak_local_max(
                    image,
                    min_distance=10,
                    threshold_abs=np.percentile(image, 70),
                    exclude_border=True,
                    indices=False
                )
                markers = measure.label(local_maxima)
            
            # Apply watershed
            labels = segmentation.watershed(gradient, markers, mask=image > 0)
            
            return labels.astype(np.uint8)
            
        except Exception as e:
            self.logger.error(f"Watershed segmentation failed: {e}")
            # Fallback to thresholding
            threshold = filters.threshold_otsu(image)
            return (image > threshold).astype(np.uint8)
    
    def _validate_segmentation(self, segmented: np.ndarray, original: np.ndarray) -> Dict[str, float]:
        """
        Validate segmentation quality with various metrics.
        
        Args:
            segmented: Segmented image
            original: Original image
            
        Returns:
            Dictionary of validation metrics
        """
        metrics = {}
        
        try:
            # Coverage metrics
            total_pixels = original.size
            segmented_pixels = np.sum(segmented > 0)
            metrics['coverage_ratio'] = segmented_pixels / total_pixels
            
            # Region properties
            labeled = measure.label(segmented)
            regions = measure.regionprops(labeled)
            
            if regions:
                areas = [region.area for region in regions]
                metrics['num_regions'] = len(regions)
                metrics['mean_region_area'] = np.mean(areas)
                metrics['std_region_area'] = np.std(areas)
                
                # Compactness (circularity) metrics
                compactness = []
                for region in regions:
                    if region.area > 10:  # Skip very small regions
                        perimeter = region.perimeter
                        if perimeter > 0:
                            compactness.append((4 * np.pi * region.area) / (perimeter ** 2))
                
                if compactness:
                    metrics['mean_compactness'] = np.mean(compactness)
                    metrics['std_compactness'] = np.std(compactness)
            
            # Intensity-based metrics
            foreground_intensity = original[segmented > 0]
            background_intensity = original[segmented == 0]
            
            if len(foreground_intensity) > 0 and len(background_intensity) > 0:
                metrics['foreground_mean'] = np.mean(foreground_intensity)
                metrics['background_mean'] = np.mean(background_intensity)
                metrics['contrast_ratio'] = (
                    np.mean(foreground_intensity) / np.mean(background_intensity)
                    if np.mean(background_intensity) > 0 else np.inf
                )
                
        except Exception as e:
            self.logger.error(f"Segmentation validation failed: {e}")
            metrics['error'] = str(e)
        
        return metrics
    
    # Private methods for internal processing
    
    def _load_raw_image(self, image_path: Path) -> np.ndarray:
        """
        Load raw iQID image data.
        
        Migrated from legacy process_object.py load methods.
        """
        try:
            if image_path.suffix.lower() in ['.dat', '.raw']:
                # Handle binary iQID format (migrated from ClusterData.load_cluster_data)
                return self._load_iqid_binary_data(image_path)
            else:
                # Handle standard image formats
                from skimage import io
                return io.imread(str(image_path))
        except Exception as e:
            self.logger.error(f"Failed to load image {image_path}: {e}")
            raise
    
    def _load_iqid_binary_data(self, file_path: Path) -> np.ndarray:
        """
        Load binary iQID data format.
        
        Migrated from ClusterData.load_cluster_data() and init_header().
        """
        # Read header to get dimensions
        header = np.fromfile(str(file_path), dtype=np.int32, count=100)
        header_size = header[0]
        xdim = header[1]
        ydim = header[2]
        
        file_size_bytes = os.path.getsize(str(file_path))
        
        # Determine data type and number of elements based on file structure
        # For processed listmode data
        num_data_elements = 14  # Default for processed_lm format
        
        byte_size = 8  # Using float64
        byte_fac = 2
        
        num_clusters = np.floor(
            (file_size_bytes - 4 * header_size) / (byte_size * num_data_elements))
        
        # Load the data
        unshaped_data = np.fromfile(
            str(file_path), 
            dtype=np.float64, 
            count=header_size // byte_fac + int(num_clusters * num_data_elements)
        )
        
        data = unshaped_data[header_size // byte_fac:].reshape(
            int(num_data_elements), int(num_clusters), order='F'
        )
        
        # Extract coordinate data (migrated from init_metadata)
        yC_global = data[4, :]  # Y coordinates
        xC_global = data[5, :]  # X coordinates
        cluster_area = data[3, :]  # Cluster areas
        sum_cluster_signal = data[2, :]  # Signal intensities
        
        # Create 2D image from coordinate data
        image = np.zeros((ydim, xdim), dtype=np.float64)
        
        # Populate image with cluster data
        for i in range(len(xC_global)):
            x_coord = int(np.clip(xC_global[i], 0, xdim - 1))
            y_coord = int(np.clip(yC_global[i], 0, ydim - 1))
            
            # Use signal intensity if available, otherwise use area
            intensity = sum_cluster_signal[i] if len(sum_cluster_signal) > i else cluster_area[i]
            image[y_coord, x_coord] = intensity
        
        return image
    
    def _preprocess_raw_image(self, raw_image: np.ndarray) -> np.ndarray:
        """
        Preprocess raw image for segmentation.
        
        Applies noise reduction, normalization, and enhancement.
        """
        # Normalize the image
        preprocessed = normalize_array(raw_image, method='minmax')
        
        # Apply gentle smoothing to reduce noise while preserving edges
        if HAS_SKIMAGE:
            preprocessed = filters.gaussian(preprocessed, sigma=1.0, preserve_range=True)
        
        return preprocessed
    
    def _detect_tissue_regions(self, image: np.ndarray) -> List[Dict[str, Any]]:
        """
        Detect tissue regions using the specified segmentation method.
        
        Migrated and enhanced from adaptive_segmentation.py
        """
        if self.method == 'adaptive_clustering':
            return self._clustering_based_segmentation(image)
        elif self.method == 'multi_threshold':
            return self._multi_threshold_segmentation(image)
        elif self.method == 'watershed':
            return self._watershed_segmentation(image)
        elif self.method == 'combined':
            return self._combined_segmentation(image)
        else:
            self.logger.warning(f"Unknown method {self.method}, using adaptive_clustering")
            return self._clustering_based_segmentation(image)
    
    def _clustering_based_segmentation(self, image: np.ndarray) -> List[Dict[str, Any]]:
        """
        Use clustering to group distributed dots into tissue blobs.
        
        Migrated from adaptive_segmentation.py
        """
        self.logger.debug("Running clustering-based segmentation")
        
        # Detect individual activity dots
        dot_positions = self._detect_activity_dots(image)
        
        if len(dot_positions) < 2:
            self.logger.debug("Not enough dots for clustering, using threshold fallback")
            return self._fallback_threshold_segmentation(image)
        
        # Cluster dots into tissue groups
        tissue_clusters = self._cluster_dots_into_tissues(dot_positions, image)
        
        # Create tissue regions from clusters
        regions = self._create_regions_from_clusters(image, tissue_clusters, dot_positions)
        
        self.logger.debug(f"Detected {len(regions)} tissue regions from {len(dot_positions)} dots")
        return regions
    
    def _detect_activity_dots(self, image: np.ndarray) -> np.ndarray:
        """
        Detect individual activity dots/peaks in the image.
        
        Enhanced implementation migrated from adaptive_segmentation.py
        Uses multiple approaches to detect weak signals.
        """
        # Method 1: Local maxima detection with adaptive thresholds
        if HAS_SKIMAGE:
            # Calculate adaptive threshold
            non_zero_values = image[image > 0]
            if len(non_zero_values) > 0:
                threshold_abs = np.percentile(non_zero_values, 15)
            else:
                threshold_abs = 0
            
            local_maxima = feature.peak_local_max(
                image,
                min_distance=3,
                threshold_abs=threshold_abs,
                threshold_rel=0.1
            )
            
            dots_maxima = np.column_stack(local_maxima) if len(local_maxima[0]) > 0 else np.array([]).reshape(0, 2)
        else:
            dots_maxima = np.array([]).reshape(0, 2)
        
        # Method 2: Connected components on low threshold
        non_zero_values = image[image > 0]
        if len(non_zero_values) > 0:
            low_threshold = np.percentile(non_zero_values, 25)
        else:
            low_threshold = 0
            
        binary_low = image > low_threshold
        
        # Minimal noise removal to preserve blob structure
        if self.preserve_blobs:
            kernel_spike = np.ones((2, 2), np.uint8)
            binary_cleaned = cv2.morphologyEx(binary_low.astype(np.uint8), cv2.MORPH_OPEN, kernel_spike)
        else:
            # More aggressive noise removal
            kernel = np.ones((3, 3), np.uint8)
            binary_cleaned = cv2.morphologyEx(binary_low.astype(np.uint8), cv2.MORPH_OPEN, kernel)
        
        # Find centroids of small connected components (individual dots)
        if HAS_SKIMAGE:
            labeled = measure.label(binary_cleaned)
            dots_cc = []
            
            for region in measure.regionprops(labeled):
                if 1 <= region.area <= 50:  # Individual dots should be small
                    dots_cc.append(region.centroid)
            
            dots_cc = np.array(dots_cc) if dots_cc else np.array([]).reshape(0, 2)
        else:
            dots_cc = np.array([]).reshape(0, 2)
        
        # Method 3: Additional peak detection using gradient-based approach
        if HAS_SKIMAGE:
            # Use gradient magnitude to find edges/peaks
            grad_magnitude = np.sqrt(
                filters.sobel_h(image)**2 + filters.sobel_v(image)**2
            )
            
            # Find peaks in gradient magnitude
            grad_threshold = np.percentile(grad_magnitude[grad_magnitude > 0], 90) if np.any(grad_magnitude > 0) else 0
            grad_peaks = feature.peak_local_max(
                grad_magnitude,
                min_distance=2,
                threshold_abs=grad_threshold * 0.5
            )
            
            dots_gradient = np.column_stack(grad_peaks) if len(grad_peaks[0]) > 0 else np.array([]).reshape(0, 2)
        else:
            dots_gradient = np.array([]).reshape(0, 2)
        
        # Combine all detection methods
        all_dots_list = []
        for dots in [dots_maxima, dots_cc, dots_gradient]:
            if len(dots) > 0:
                all_dots_list.append(dots)
        
        if all_dots_list:
            all_dots = np.vstack(all_dots_list)
            
            # Remove duplicate detections (dots within 2 pixels of each other)
            if len(all_dots) > 1:
                from scipy.spatial.distance import pdist, squareform
                distances = squareform(pdist(all_dots))
                np.fill_diagonal(distances, np.inf)  # Ignore self-distances
                
                # Find duplicates
                duplicate_mask = np.zeros(len(all_dots), dtype=bool)
                for i in range(len(all_dots)):
                    if duplicate_mask[i]:
                        continue
                    close_points = np.where(distances[i] < 2.0)[0]
                    if len(close_points) > 0:
                        # Keep the first point, mark others as duplicates
                        duplicate_mask[close_points] = True
                
                all_dots = all_dots[~duplicate_mask]
        else:
            all_dots = np.array([]).reshape(0, 2)
        
        self.logger.debug(f"Detected {len(all_dots)} activity dots using combined methods")
        return all_dots
    
    def _cluster_dots_into_tissues(self, dot_positions: np.ndarray, image: np.ndarray) -> List[List[int]]:
        """
        Cluster nearby dots into tissue groups using multiple clustering methods.
        
        Enhanced implementation with adaptive clustering approach.
        """
        if len(dot_positions) < 2:
            return []
        
        self.logger.debug(f"Clustering {len(dot_positions)} dots into tissue groups")
        
        # Method 1: Hierarchical clustering (primary method)
        try:
            distances = pdist(dot_positions)
            if len(distances) == 0:
                return [list(range(len(dot_positions)))]
                
            linkage_matrix = linkage(distances, method='ward')
            
            # Adaptive cluster count based on image characteristics
            image_area = image.shape[0] * image.shape[1]
            dot_density = len(dot_positions) / image_area
            
            # Estimate number of tissues based on dot distribution
            if dot_density > 0.001:  # High density - likely more tissues
                max_clusters = min(6, max(2, len(dot_positions) // 5))
            else:  # Lower density - fewer tissues
                max_clusters = min(4, max(2, len(dot_positions) // 8))
            
            if max_clusters < 2:
                return [list(range(len(dot_positions)))]
            
            cluster_labels = fcluster(linkage_matrix, max_clusters, criterion='maxclust')
            
            # Group dot indices by cluster
            clusters = []
            for cluster_id in range(1, max_clusters + 1):
                cluster_dots = [i for i, label in enumerate(cluster_labels) if label == cluster_id]
                if len(cluster_dots) >= 2:  # Only keep clusters with multiple dots
                    clusters.append(cluster_dots)
            
            if clusters:
                self.logger.debug(f"Hierarchical clustering found {len(clusters)} tissue clusters")
                return clusters
            
        except Exception as e:
            self.logger.warning(f"Hierarchical clustering failed: {e}")
        
        # Method 2: DBSCAN clustering (fallback)
        if HAS_SKLEARN and self.use_clustering:
            try:
                # Adaptive epsilon based on image size
                eps = max(10, min(50, np.sqrt(image.shape[0] * image.shape[1]) / 20))
                min_samples = max(2, len(dot_positions) // 10)
                
                dbscan = DBSCAN(eps=eps, min_samples=min_samples)
                cluster_labels = dbscan.fit_predict(dot_positions)
                
                # Group dots by cluster (ignore noise points labeled as -1)
                clusters = []
                unique_labels = set(cluster_labels) - {-1}
                
                for label in unique_labels:
                    cluster_dots = [i for i, l in enumerate(cluster_labels) if l == label]
                    if len(cluster_dots) >= 2:
                        clusters.append(cluster_dots)
                
                if clusters:
                    self.logger.debug(f"DBSCAN clustering found {len(clusters)} tissue clusters")
                    return clusters
                    
            except Exception as e:
                self.logger.warning(f"DBSCAN clustering failed: {e}")
        
        # Method 3: Distance-based grouping (final fallback)
        return self._simple_distance_clustering(dot_positions, image)
    
    def _simple_distance_clustering(self, dot_positions: np.ndarray, image: np.ndarray) -> List[List[int]]:
        """
        Simple distance-based clustering as a fallback method.
        """
        if len(dot_positions) < 2:
            return [list(range(len(dot_positions)))]
        
        # Use simple distance threshold
        distance_threshold = max(20, min(100, np.sqrt(image.shape[0] * image.shape[1]) / 15))
        
        clusters = []
        unassigned = list(range(len(dot_positions)))
        
        while unassigned:
            # Start new cluster with first unassigned point
            current_cluster = [unassigned.pop(0)]
            
            # Find all points within distance threshold
            changed = True
            while changed:
                changed = False
                for i in list(unassigned):
                    # Check distance to any point in current cluster
                    min_dist = min([
                        np.linalg.norm(dot_positions[i] - dot_positions[j])
                        for j in current_cluster
                    ])
                    
                    if min_dist <= distance_threshold:
                        current_cluster.append(i)
                        unassigned.remove(i)
                        changed = True
            
            if len(current_cluster) >= 2:  # Only keep clusters with multiple dots
                clusters.append(current_cluster)
        
        self.logger.debug(f"Distance-based clustering found {len(clusters)} tissue clusters")
        return clusters
    
    def _create_regions_from_clusters(self, image: np.ndarray, clusters: List[List[int]], dot_positions: np.ndarray) -> List[Dict[str, Any]]:
        """
        Create tissue region descriptors from dot clusters.
        """
        regions = []
        
        for i, cluster_indices in enumerate(clusters):
            if not cluster_indices:
                continue
            
            cluster_dots = dot_positions[cluster_indices]
            
            # Calculate cluster properties
            centroid = np.mean(cluster_dots, axis=0)
            
            # Create bounding box around cluster
            min_row, min_col = np.min(cluster_dots, axis=0)
            max_row, max_col = np.max(cluster_dots, axis=0)
            
            # Expand bounding box slightly
            padding = 10
            bbox = (
                max(0, int(min_row - padding)),
                max(0, int(min_col - padding)),
                min(image.shape[0], int(max_row + padding)),
                min(image.shape[1], int(max_col + padding))
            )
            
            # Extract region from image
            region_image = image[bbox[0]:bbox[2], bbox[1]:bbox[3]]
            
            # Estimate area based on cluster size and local image intensity
            estimated_area = len(cluster_indices) * 10  # Rough estimate
            
            region_info = {
                'cluster_id': i,
                'centroid': centroid,
                'bbox': bbox,
                'area': estimated_area,
                'dot_count': len(cluster_indices),
                'dot_positions': cluster_dots,
                'region_image': region_image
            }
            
            regions.append(region_info)
        
        return regions
    
    def _multi_threshold_segmentation(self, image: np.ndarray, num_thresholds: int = 3) -> np.ndarray:
        """
        Apply multi-level thresholding for tissue separation.
        
        Args:
            image: Input grayscale image
            num_thresholds: Number of threshold levels
            
        Returns:
            Multi-level segmented image
        """
        try:
            # Apply Gaussian filter to reduce noise
            filtered = filters.gaussian(image, sigma=1.0)
            
            # Use Otsu's method with multiple thresholds
            thresholds = filters.threshold_multiotsu(filtered, classes=num_thresholds + 1)
            
            # Create multi-level segmentation
            segmented = np.digitize(filtered, thresholds)
            
            return segmented.astype(np.uint8)
            
        except Exception as e:
            self.logger.error(f"Multi-threshold segmentation failed: {e}")
            # Fallback to simple binary threshold
            threshold = filters.threshold_otsu(image)
            return (image > threshold).astype(np.uint8)
    
    def _watershed_segmentation(self, image: np.ndarray, markers: Optional[np.ndarray] = None) -> np.ndarray:
        """
        Apply watershed segmentation for tissue separation.
        
        Args:
            image: Input grayscale image
            markers: Optional marker image for seeded watershed
            
        Returns:
            Watershed segmented image
        """
        try:
            # Compute gradient magnitude
            gradient = filters.sobel(image)
            
            if markers is None:
                # Auto-generate markers using local maxima
                local_maxima = feature.peak_local_max(
                    image,
                    min_distance=10,
                    threshold_abs=np.percentile(image, 70),
                    exclude_border=True,
                    indices=False
                )
                markers = measure.label(local_maxima)
            
            # Apply watershed
            labels = segmentation.watershed(gradient, markers, mask=image > 0)
            
            return labels.astype(np.uint8)
            
        except Exception as e:
            self.logger.error(f"Watershed segmentation failed: {e}")
            # Fallback to thresholding
            threshold = filters.threshold_otsu(image)
            return (image > threshold).astype(np.uint8)
    
    def _validate_segmentation(self, segmented: np.ndarray, original: np.ndarray) -> Dict[str, float]:
        """
        Validate segmentation quality with various metrics.
        
        Args:
            segmented: Segmented image
            original: Original image
            
        Returns:
            Dictionary of validation metrics
        """
        metrics = {}
        
        try:
            # Coverage metrics
            total_pixels = original.size
            segmented_pixels = np.sum(segmented > 0)
            metrics['coverage_ratio'] = segmented_pixels / total_pixels
            
            # Region properties
            labeled = measure.label(segmented)
            regions = measure.regionprops(labeled)
            
            if regions:
                areas = [region.area for region in regions]
                metrics['num_regions'] = len(regions)
                metrics['mean_region_area'] = np.mean(areas)
                metrics['std_region_area'] = np.std(areas)
                
                # Compactness (circularity) metrics
                compactness = []
                for region in regions:
                    if region.area > 10:  # Skip very small regions
                        perimeter = region.perimeter
                        if perimeter > 0:
                            compactness.append((4 * np.pi * region.area) / (perimeter ** 2))
                
                if compactness:
                    metrics['mean_compactness'] = np.mean(compactness)
                    metrics['std_compactness'] = np.std(compactness)
            
            # Intensity-based metrics
            foreground_intensity = original[segmented > 0]
            background_intensity = original[segmented == 0]
            
            if len(foreground_intensity) > 0 and len(background_intensity) > 0:
                metrics['foreground_mean'] = np.mean(foreground_intensity)
                metrics['background_mean'] = np.mean(background_intensity)
                metrics['contrast_ratio'] = (
                    np.mean(foreground_intensity) / np.mean(background_intensity)
                    if np.mean(background_intensity) > 0 else np.inf
                )
                
        except Exception as e:
            self.logger.error(f"Segmentation validation failed: {e}")
            metrics['error'] = str(e)
        
        return metrics
    
    # Private methods for internal processing
    
    def _load_raw_image(self, image_path: Path) -> np.ndarray:
        """
        Load raw iQID image data.
        
        Migrated from legacy process_object.py load methods.
        """
        try:
            if image_path.suffix.lower() in ['.dat', '.raw']:
                # Handle binary iQID format (migrated from ClusterData.load_cluster_data)
                return self._load_iqid_binary_data(image_path)
            else:
                # Handle standard image formats
                from skimage import io
                return io.imread(str(image_path))
        except Exception as e:
            self.logger.error(f"Failed to load image {image_path}: {e}")
            raise
    
    def _load_iqid_binary_data(self, file_path: Path) -> np.ndarray:
        """
        Load binary iQID data format.
        
        Migrated from ClusterData.load_cluster_data() and init_header().
        """
        # Read header to get dimensions
        header = np.fromfile(str(file_path), dtype=np.int32, count=100)
        header_size = header[0]
        xdim = header[1]
        ydim = header[2]
        
        file_size_bytes = os.path.getsize(str(file_path))
        
        # Determine data type and number of elements based on file structure
        # For processed listmode data
        num_data_elements = 14  # Default for processed_lm format
        
        byte_size = 8  # Using float64
        byte_fac = 2
        
        num_clusters = np.floor(
            (file_size_bytes - 4 * header_size) / (byte_size * num_data_elements))
        
        # Load the data
        unshaped_data = np.fromfile(
            str(file_path), 
            dtype=np.float64, 
            count=header_size // byte_fac + int(num_clusters * num_data_elements)
        )
        
        data = unshaped_data[header_size // byte_fac:].reshape(
            int(num_data_elements), int(num_clusters), order='F'
        )
        
        # Extract coordinate data (migrated from init_metadata)
        yC_global = data[4, :]  # Y coordinates
        xC_global = data[5, :]  # X coordinates
        cluster_area = data[3, :]  # Cluster areas
        sum_cluster_signal = data[2, :]  # Signal intensities
        
        # Create 2D image from coordinate data
        image = np.zeros((ydim, xdim), dtype=np.float64)
        
        # Populate image with cluster data
        for i in range(len(xC_global)):
            x_coord = int(np.clip(xC_global[i], 0, xdim - 1))
            y_coord = int(np.clip(yC_global[i], 0, ydim - 1))
            
            # Use signal intensity if available, otherwise use area
            intensity = sum_cluster_signal[i] if len(sum_cluster_signal) > i else cluster_area[i]
            image[y_coord, x_coord] = intensity
        
        return image
    
    def _preprocess_raw_image(self, raw_image: np.ndarray) -> np.ndarray:
        """
        Preprocess raw image for segmentation.
        
        Applies noise reduction, normalization, and enhancement.
        """
        # Normalize the image
        preprocessed = normalize_array(raw_image, method='minmax')
        
        # Apply gentle smoothing to reduce noise while preserving edges
        if HAS_SKIMAGE:
            preprocessed = filters.gaussian(preprocessed, sigma=1.0, preserve_range=True)
        
        return preprocessed
    
    def _detect_tissue_regions(self, image: np.ndarray) -> List[Dict[str, Any]]:
        """
        Detect tissue regions using the specified segmentation method.
        
        Migrated and enhanced from adaptive_segmentation.py
        """
        if self.method == 'adaptive_clustering':
            return self._clustering_based_segmentation(image)
        elif self.method == 'multi_threshold':
            return self._multi_threshold_segmentation(image)
        elif self.method == 'watershed':
            return self._watershed_segmentation(image)
        elif self.method == 'combined':
            return self._combined_segmentation(image)
        else:
            self.logger.warning(f"Unknown method {self.method}, using adaptive_clustering")
            return self._clustering_based_segmentation(image)
    
    def _clustering_based_segmentation(self, image: np.ndarray) -> List[Dict[str, Any]]:
        """
        Use clustering to group distributed dots into tissue blobs.
        
        Migrated from adaptive_segmentation.py
        """
        self.logger.debug("Running clustering-based segmentation")
        
        # Detect individual activity dots
        dot_positions = self._detect_activity_dots(image)
        
        if len(dot_positions) < 2:
            self.logger.debug("Not enough dots for clustering, using threshold fallback")
            return self._fallback_threshold_segmentation(image)
        
        # Cluster dots into tissue groups
        tissue_clusters = self._cluster_dots_into_tissues(dot_positions, image)
        
        # Create tissue regions from clusters
        regions = self._create_regions_from_clusters(image, tissue_clusters, dot_positions)
        
        self.logger.debug(f"Detected {len(regions)} tissue regions from {len(dot_positions)} dots")
        return regions
    
    def _detect_activity_dots(self, image: np.ndarray) -> np.ndarray:
        """
        Detect individual activity dots/peaks in the image.
        
        Enhanced implementation migrated from adaptive_segmentation.py
        Uses multiple approaches to detect weak signals.
        """
        # Method 1: Local maxima detection with adaptive thresholds
        if HAS_SKIMAGE:
            # Calculate adaptive threshold
            non_zero_values = image[image > 0]
            if len(non_zero_values) > 0:
                threshold_abs = np.percentile(non_zero_values, 15)
            else:
                threshold_abs = 0
            
            local_maxima = feature.peak_local_max(
                image,
                min_distance=3,
                threshold_abs=threshold_abs,
                threshold_rel=0.1
            )
            
            dots_maxima = np.column_stack(local_maxima) if len(local_maxima[0]) > 0 else np.array([]).reshape(0, 2)
        else:
            dots_maxima = np.array([]).reshape(0, 2)
        
        # Method 2: Connected components on low threshold
        non_zero_values = image[image > 0]
        if len(non_zero_values) > 0:
            low_threshold = np.percentile(non_zero_values, 25)
        else:
            low_threshold = 0
            
        binary_low = image > low_threshold
        
        # Minimal noise removal to preserve blob structure
        if self.preserve_blobs:
            kernel_spike = np.ones((2, 2), np.uint8)
            binary_cleaned = cv2.morphologyEx(binary_low.astype(np.uint8), cv2.MORPH_OPEN, kernel_spike)
        else:
            # More aggressive noise removal
            kernel = np.ones((3, 3), np.uint8)
            binary_cleaned = cv2.morphologyEx(binary_low.astype(np.uint8), cv2.MORPH_OPEN, kernel)
        
        # Find centroids of small connected components (individual dots)
        if HAS_SKIMAGE:
            labeled = measure.label(binary_cleaned)
            dots_cc = []
            
            for region in measure.regionprops(labeled):
                if 1 <= region.area <= 50:  # Individual dots should be small
                    dots_cc.append(region.centroid)
            
            dots_cc = np.array(dots_cc) if dots_cc else np.array([]).reshape(0, 2)
        else:
            dots_cc = np.array([]).reshape(0, 2)
        
        # Method 3: Additional peak detection using gradient-based approach
        if HAS_SKIMAGE:
            # Use gradient magnitude to find edges/peaks
            grad_magnitude = np.sqrt(
                filters.sobel_h(image)**2 + filters.sobel_v(image)**2
            )
            
            # Find peaks in gradient magnitude
            grad_threshold = np.percentile(grad_magnitude[grad_magnitude > 0], 90) if np.any(grad_magnitude > 0) else 0
            grad_peaks = feature.peak_local_max(
                grad_magnitude,
                min_distance=2,
                threshold_abs=grad_threshold * 0.5
            )
            
            dots_gradient = np.column_stack(grad_peaks) if len(grad_peaks[0]) > 0 else np.array([]).reshape(0, 2)
        else:
            dots_gradient = np.array([]).reshape(0, 2)
        
        # Combine all detection methods
        all_dots_list = []
        for dots in [dots_maxima, dots_cc, dots_gradient]:
            if len(dots) > 0:
                all_dots_list.append(dots)
        
        if all_dots_list:
            all_dots = np.vstack(all_dots_list)
            
            # Remove duplicate detections (dots within 2 pixels of each other)
            if len(all_dots) > 1:
                from scipy.spatial.distance import pdist, squareform
                distances = squareform(pdist(all_dots))
                np.fill_diagonal(distances, np.inf)  # Ignore self-distances
                
                # Find duplicates
                duplicate_mask = np.zeros(len(all_dots), dtype=bool)
                for i in range(len(all_dots)):
                    if duplicate_mask[i]:
                        continue
                    close_points = np.where(distances[i] < 2.0)[0]
                    if len(close_points) > 0:
                        # Keep the first point, mark others as duplicates
                        duplicate_mask[close_points] = True
                
                all_dots = all_dots[~duplicate_mask]
        else:
            all_dots = np.array([]).reshape(0, 2)
        
        self.logger.debug(f"Detected {len(all_dots)} activity dots using combined methods")
        return all_dots
    
    def _cluster_dots_into_tissues(self, dot_positions: np.ndarray, image: np.ndarray) -> List[List[int]]:
        """
        Cluster nearby dots into tissue groups using multiple clustering methods.
        
        Enhanced implementation with adaptive clustering approach.
        """
        if len(dot_positions) < 2:
            return []
        
        self.logger.debug(f"Clustering {len(dot_positions)} dots into tissue groups")
        
        # Method 1: Hierarchical clustering (primary method)
        try:
            distances = pdist(dot_positions)
            if len(distances) == 0:
                return [list(range(len(dot_positions)))]
                
            linkage_matrix = linkage(distances, method='ward')
            
            # Adaptive cluster count based on image characteristics
            image_area = image.shape[0] * image.shape[1]
            dot_density = len(dot_positions) / image_area
            
            # Estimate number of tissues based on dot distribution
            if dot_density > 0.001:  # High density - likely more tissues
                max_clusters = min(6, max(2, len(dot_positions) // 5))
            else:  # Lower density - fewer tissues
                max_clusters = min(4, max(2, len(dot_positions) // 8))
            
            if max_clusters < 2:
                return [list(range(len(dot_positions)))]
            
            cluster_labels = fcluster(linkage_matrix, max_clusters, criterion='maxclust')
            
            # Group dot indices by cluster
            clusters = []
            for cluster_id in range(1, max_clusters + 1):
                cluster_dots = [i for i, label in enumerate(cluster_labels) if label == cluster_id]
                if len(cluster_dots) >= 2:  # Only keep clusters with multiple dots
                    clusters.append(cluster_dots)
            
            if clusters:
                self.logger.debug(f"Hierarchical clustering found {len(clusters)} tissue clusters")
                return clusters
            
        except Exception as e:
            self.logger.warning(f"Hierarchical clustering failed: {e}")
        
        # Method 2: DBSCAN clustering (fallback)
        if HAS_SKLEARN and self.use_clustering:
            try:
                # Adaptive epsilon based on image size
                eps = max(10, min(50, np.sqrt(image.shape[0] * image.shape[1]) / 20))
                min_samples = max(2, len(dot_positions) // 10)
                
                dbscan = DBSCAN(eps=eps, min_samples=min_samples)
                cluster_labels = dbscan.fit_predict(dot_positions)
                
                # Group dots by cluster (ignore noise points labeled as -1)
                clusters = []
                unique_labels = set(cluster_labels) - {-1}
                
                for label in unique_labels:
                    cluster_dots = [i for i, l in enumerate(cluster_labels) if l == label]
                    if len(cluster_dots) >= 2:
                        clusters.append(cluster_dots)
                
                if clusters:
                    self.logger.debug(f"DBSCAN clustering found {len(clusters)} tissue clusters")
                    return clusters
                    
            except Exception as e:
                self.logger.warning(f"DBSCAN clustering failed: {e}")
        
        # Method 3: Distance-based grouping (final fallback)
        return self._simple_distance_clustering(dot_positions, image)
    
    def _simple_distance_clustering(self, dot_positions: np.ndarray, image: np.ndarray) -> List[List[int]]:
        """
        Simple distance-based clustering as a fallback method.
        """
        if len(dot_positions) < 2:
            return [list(range(len(dot_positions)))]
        
        # Use simple distance threshold
        distance_threshold = max(20, min(100, np.sqrt(image.shape[0] * image.shape[1]) / 15))
        
        clusters = []
        unassigned = list(range(len(dot_positions)))
        
        while unassigned:
            # Start new cluster with first unassigned point
            current_cluster = [unassigned.pop(0)]
            
            # Find all points within distance threshold
            changed = True
            while changed:
                changed = False
                for i in list(unassigned):
                    # Check distance to any point in current cluster
                    min_dist = min([
                        np.linalg.norm(dot_positions[i] - dot_positions[j])
                        for j in current_cluster
                    ])
                    
                    if min_dist <= distance_threshold:
                        current_cluster.append(i)
                        unassigned.remove(i)
                        changed = True
            
            if len(current_cluster) >= 2:  # Only keep clusters with multiple dots
                clusters.append(current_cluster)
        
        self.logger.debug(f"Distance-based clustering found {len(clusters)} tissue clusters")
        return clusters
    
    def _create_regions_from_clusters(self, image: np.ndarray, clusters: List[List[int]], dot_positions: np.ndarray) -> List[Dict[str, Any]]:
        """
        Create tissue region descriptors from dot clusters.
        """
        regions = []
        
        for i, cluster_indices in enumerate(clusters):
            if not cluster_indices:
                continue
            
            cluster_dots = dot_positions[cluster_indices]
            
            # Calculate cluster properties
            centroid = np.mean(cluster_dots, axis=0)
            
            # Create bounding box around cluster
            min_row, min_col = np.min(cluster_dots, axis=0)
            max_row, max_col = np.max(cluster_dots, axis=0)
            
            # Expand bounding box slightly
            padding = 10
            bbox = (
                max(0, int(min_row - padding)),
                max(0, int(min_col - padding)),
                min(image.shape[0], int(max_row + padding)),
                min(image.shape[1], int(max_col + padding))
            )
            
            # Extract region from image
            region_image = image[bbox[0]:bbox[2], bbox[1]:bbox[3]]
            
            # Estimate area based on cluster size and local image intensity
            estimated_area = len(cluster_indices) * 10  # Rough estimate
            
            region_info = {
                'cluster_id': i,
                'centroid': centroid,
                'bbox': bbox,
                'area': estimated_area,
                'dot_count': len(cluster_indices),
                'dot_positions': cluster_dots,
                'region_image': region_image
            }
            
            regions.append(region_info)
        
        return regions
    
    def _multi_threshold_segmentation(self, image: np.ndarray, num_thresholds: int = 3) -> np.ndarray:
        """
        Apply multi-level thresholding for tissue separation.
        
        Args:
            image: Input grayscale image
            num_thresholds: Number of threshold levels
            
        Returns:
            Multi-level segmented image
        """
        try:
            # Apply Gaussian filter to reduce noise
            filtered = filters.gaussian(image, sigma=1.0)
            
            # Use Otsu's method with multiple thresholds
            thresholds = filters.threshold_multiotsu(filtered, classes=num_thresholds + 1)
            
            # Create multi-level segmentation
            segmented = np.digitize(filtered, thresholds)
            
            return segmented.astype(np.uint8)
            
        except Exception as e:
            self.logger.error(f"Multi-threshold segmentation failed: {e}")
            # Fallback to simple binary threshold
            threshold = filters.threshold_otsu(image)
            return (image > threshold).astype(np.uint8)
    
    def _watershed_segmentation(self, image: np.ndarray, markers: Optional[np.ndarray] = None) -> np.ndarray:
        """
        Apply watershed segmentation for tissue separation.
        
        Args:
            image: Input grayscale image
            markers: Optional marker image for seeded watershed
            
        Returns:
            Watershed segmented image
        """
        try:
            # Compute gradient magnitude
            gradient = filters.sobel(image)
            
            if markers is None:
                # Auto-generate markers using local maxima
                local_maxima = feature.peak_local_max(
                    image,
                    min_distance=10,
                    threshold_abs=np.percentile(image, 70),
                    exclude_border=True,
                    indices=False
                )
                markers = measure.label(local_maxima)
            
            # Apply watershed
            labels = segmentation.watershed(gradient, markers, mask=image > 0)
            
            return labels.astype(np.uint8)
            
        except Exception as e:
            self.logger.error(f"Watershed segmentation failed: {e}")
            # Fallback to thresholding
            threshold = filters.threshold_otsu(image)
            return (image > threshold).astype(np.uint8)
    
    def _validate_segmentation(self, segmented: np.ndarray, original: np.ndarray) -> Dict[str, float]:
        """
        Validate segmentation quality with various metrics.
        
        Args:
            segmented: Segmented image
            original: Original image
            
        Returns:
            Dictionary of validation metrics
        """
        metrics = {}
        
        try:
            # Coverage metrics
            total_pixels = original.size
            segmented_pixels = np.sum(segmented > 0)
            metrics['coverage_ratio'] = segmented_pixels / total_pixels
            
            # Region properties
            labeled = measure.label(segmented)
            regions = measure.regionprops(labeled)
            
            if regions:
                areas = [region.area for region in regions]
                metrics['num_regions'] = len(regions)
                metrics['mean_region_area'] = np.mean(areas)
                metrics['std_region_area'] = np.std(areas)
                
                # Compactness (circularity) metrics
                compactness = []
                for region in regions:
                    if region.area > 10:  # Skip very small regions
                        perimeter = region.perimeter
                        if perimeter > 0:
                            compactness.append((4 * np.pi * region.area) / (perimeter ** 2))
                
                if compactness:
                    metrics['mean_compactness'] = np.mean(compactness)
                    metrics['std_compactness'] = np.std(compactness)
            
            # Intensity-based metrics
            foreground_intensity = original[segmented > 0]
            background_intensity = original[segmented == 0]
            
            if len(foreground_intensity) > 0 and len(background_intensity) > 0:
                metrics['foreground_mean'] = np.mean(foreground_intensity)
                metrics['background_mean'] = np.mean(background_intensity)
                metrics['contrast_ratio'] = (
                    np.mean(foreground_intensity) / np.mean(background_intensity)
                    if np.mean(background_intensity) > 0 else np.inf
                )
                
        except Exception as e:
            self.logger.error(f"Segmentation validation failed: {e}")
            metrics['error'] = str(e)
        
        return metrics
    
    # Private methods for internal processing
    
    def _load_raw_image(self, image_path: Path) -> np.ndarray:
        """
        Load raw iQID image data.
        
        Migrated from legacy process_object.py load methods.
        """
        try:
            if image_path.suffix.lower() in ['.dat', '.raw']:
                # Handle binary iQID format (migrated from ClusterData.load_cluster_data)
                return self._load_iqid_binary_data(image_path)
            else:
                # Handle standard image formats
                from skimage import io
                return io.imread(str(image_path))
        except Exception as e:
            self.logger.error(f"Failed to load image {image_path}: {e}")
            raise
    
    def _load_iqid_binary_data(self, file_path: Path) -> np.ndarray:
        """
        Load binary iQID data format.
        
        Migrated from ClusterData.load_cluster_data() and init_header().
        """
        # Read header to get dimensions
        header = np.fromfile(str(file_path), dtype=np.int32, count=100)
        header_size = header[0]
        xdim = header[1]
        ydim = header[2]
        
        file_size_bytes = os.path.getsize(str(file_path))
        
        # Determine data type and number of elements based on file structure
        # For processed listmode data
        num_data_elements = 14  # Default for processed_lm format
        
        byte_size = 8  # Using float64
        byte_fac = 2
        
        num_clusters = np.floor(
            (file_size_bytes - 4 * header_size) / (byte_size * num_data_elements))
        
        # Load the data
        unshaped_data = np.fromfile(
            str(file_path), 
            dtype=np.float64, 
            count=header_size // byte_fac + int(num_clusters * num_data_elements)
        )
        
        data = unshaped_data[header_size // byte_fac:].reshape(
            int(num_data_elements), int(num_clusters), order='F'
        )
        
        # Extract coordinate data (migrated from init_metadata)
        yC_global = data[4, :]  # Y coordinates
        xC_global = data[5, :]  # X coordinates
        cluster_area = data[3, :]  # Cluster areas
        sum_cluster_signal = data[2, :]  # Signal intensities
        
        # Create 2D image from coordinate data
        image = np.zeros((ydim, xdim), dtype=np.float64)
        
        # Populate image with cluster data
        for i in range(len(xC_global)):
            x_coord = int(np.clip(xC_global[i], 0, xdim - 1))
            y_coord = int(np.clip(yC_global[i], 0, ydim - 1))
            
            # Use signal intensity if available, otherwise use area
            intensity = sum_cluster_signal[i] if len(sum_cluster_signal) > i else cluster_area[i]
            image[y_coord, x_coord] = intensity
        
        return image
    
    def _preprocess_raw_image(self, raw_image: np.ndarray) -> np.ndarray:
        """
        Preprocess raw image for segmentation.
        
        Applies noise reduction, normalization, and enhancement.
        """
        # Normalize the image
        preprocessed = normalize_array(raw_image, method='minmax')
        
        # Apply gentle smoothing to reduce noise while preserving edges
        if HAS_SKIMAGE:
            preprocessed = filters.gaussian(preprocessed, sigma=1.0, preserve_range=True)
        
        return preprocessed
    
    def _detect_tissue_regions(self, image: np.ndarray) -> List[Dict[str, Any]]:
        """
        Detect tissue regions using the specified segmentation method.
        
        Migrated and enhanced from adaptive_segmentation.py
        """
        if self.method == 'adaptive_clustering':
            return self._clustering_based_segmentation(image)
        elif self.method == 'multi_threshold':
            return self._multi_threshold_segmentation(image)
        elif self.method == 'watershed':
            return self._watershed_segmentation(image)
        elif self.method == 'combined':
            return self._combined_segmentation(image)
        else:
            self.logger.warning(f"Unknown method {self.method}, using adaptive_clustering")
            return self._clustering_based_segmentation(image)
    
    def _clustering_based_segmentation(self, image: np.ndarray) -> List[Dict[str, Any]]:
        """
        Use clustering to group distributed dots into tissue blobs.
        
        Migrated from adaptive_segmentation.py
        """
        self.logger.debug("Running clustering-based segmentation")
        
        # Detect individual activity dots
        dot_positions = self._detect_activity_dots(image)
        
        if len(dot_positions) < 2:
            self.logger.debug("Not enough dots for clustering, using threshold fallback")
            return self._fallback_threshold_segmentation(image)
        
        # Cluster dots into tissue groups
        tissue_clusters = self._cluster_dots_into_tissues(dot_positions, image)
        
        # Create tissue regions from clusters
        regions = self._create_regions_from_clusters(image, tissue_clusters, dot_positions)
        
        self.logger.debug(f"Detected {len(regions)} tissue regions from {len(dot_positions)} dots")
        return regions
    
    def _detect_activity_dots(self, image: np.ndarray) -> np.ndarray:
        """
        Detect individual activity dots/peaks in the image.
        
        Enhanced implementation migrated from adaptive_segmentation.py
        Uses multiple approaches to detect weak signals.
        """
        # Method 1: Local maxima detection with adaptive thresholds
        if HAS_SKIMAGE:
            # Calculate adaptive threshold
            non_zero_values = image[image > 0]
            if len(non_zero_values) > 0:
                threshold_abs = np.percentile(non_zero_values, 15)
            else:
                threshold_abs = 0
            
            local_maxima = feature.peak_local_max(
                image,
                min_distance=3,
                threshold_abs=threshold_abs,
                threshold_rel=0.1
            )
            
            dots_maxima = np.column_stack(local_maxima) if len(local_maxima[0]) > 0 else np.array([]).reshape(0, 2)
        else:
            dots_maxima = np.array([]).reshape(0, 2)
        
        # Method 2: Connected components on low threshold
        non_zero_values = image[image > 0]
        if len(non_zero_values) > 0:
            low_threshold = np.percentile(non_zero_values, 25)
        else:
            low_threshold = 0
            
        binary_low = image > low_threshold
        
        # Minimal noise removal to preserve blob structure
        if self.preserve_blobs:
            kernel_spike = np.ones((2, 2), np.uint8)
            binary_cleaned = cv2.morphologyEx(binary_low.astype(np.uint8), cv2.MORPH_OPEN, kernel_spike)
        else:
            # More aggressive noise removal
            kernel = np.ones((3, 3), np.uint8)
            binary_cleaned = cv2.morphologyEx(binary_low.astype(np.uint8), cv2.MORPH_OPEN, kernel)
        
        # Find centroids of small connected components (individual dots)
        if HAS_SKIMAGE:
            labeled = measure.label(binary_cleaned)
            dots_cc = []
            
            for region in measure.regionprops(labeled):
                if 1 <= region.area <= 50:  # Individual dots should be small
                    dots_cc.append(region.centroid)
            
            dots_cc = np.array(dots_cc) if dots_cc else np.array([]).reshape(0, 2)
        else:
            dots_cc = np.array([]).reshape(0, 2)
        
        # Method 3: Additional peak detection using gradient-based approach
        if HAS_SKIMAGE:
            # Use gradient magnitude to find edges/peaks
            grad_magnitude = np.sqrt(
                filters.sobel_h(image)**2 + filters.sobel_v(image)**2
            )
            
            # Find peaks in gradient magnitude
            grad_threshold = np.percentile(grad_magnitude[grad_magnitude > 0], 90) if np.any(grad_magnitude > 0) else 0
            grad_peaks = feature.peak_local_max(
                grad_magnitude,
                min_distance=2,
                threshold_abs=grad_threshold * 0.5
            )
            
            dots_gradient = np.column_stack(grad_peaks) if len(grad_peaks[0]) > 0 else np.array([]).reshape(0, 2)
        else:
            dots_gradient = np.array([]).reshape(0, 2)
        
        # Combine all detection methods
        all_dots_list = []
        for dots in [dots_maxima, dots_cc, dots_gradient]:
            if len(dots) > 0:
                all_dots_list.append(dots)
        
        if all_dots_list:
            all_dots = np.vstack(all_dots_list)
            
            # Remove duplicate detections (dots within 2 pixels of each other)
            if len(all_dots) > 1:
                from scipy.spatial.distance import pdist, squareform
                distances = squareform(pdist(all_dots))
                np.fill_diagonal(distances, np.inf)  # Ignore self-distances
                
                # Find duplicates
                duplicate_mask = np.zeros(len(all_dots), dtype=bool)
                for i in range(len(all_dots)):
                    if duplicate_mask[i]:
                        continue
                    close_points = np.where(distances[i] < 2.0)[0]
                    if len(close_points) > 0:
                        # Keep the first point, mark others as duplicates
                        duplicate_mask[close_points] = True
                
                all_dots = all_dots[~duplicate_mask]
        else:
            all_dots = np.array([]).reshape(0, 2)
        
        self.logger.debug(f"Detected {len(all_dots)} activity dots using combined methods")
        return all_dots
    
    def _cluster_dots_into_tissues(self, dot_positions: np.ndarray, image: np.ndarray) -> List[List[int]]:
        """
        Cluster nearby dots into tissue groups using multiple clustering methods.
        
        Enhanced implementation with adaptive clustering approach.
        """
        if len(dot_positions) < 2:
            return []
        
        self.logger.debug(f"Clustering {len(dot_positions)} dots into tissue groups")
        
        # Method 1: Hierarchical clustering (primary method)
        try:
            distances = pdist(dot_positions)
            if len(distances) == 0:
                return [list(range(len(dot_positions)))]
                
            linkage_matrix = linkage(distances, method='ward')
            
            # Adaptive cluster count based on image characteristics
            image_area = image.shape[0] * image.shape[1]
            dot_density = len(dot_positions) / image_area
            
            # Estimate number of tissues based on dot distribution
            if dot_density > 0.001:  # High density - likely more tissues
                max_clusters = min(6, max(2, len(dot_positions) // 5))
            else:  # Lower density - fewer tissues
                max_clusters = min(4, max(2, len(dot_positions) // 8))
            
            if max_clusters < 2:
                return [list(range(len(dot_positions)))]
            
            cluster_labels = fcluster(linkage_matrix, max_clusters, criterion='maxclust')
            
            # Group dot indices by cluster
            clusters = []
            for cluster_id in range(1, max_clusters + 1):
                cluster_dots = [i for i, label in enumerate(cluster_labels) if label == cluster_id]
                if len(cluster_dots) >= 2:  # Only keep clusters with multiple dots
                    clusters.append(cluster_dots)
            
            if clusters:
                self.logger.debug(f"Hierarchical clustering found {len(clusters)} tissue clusters")
                return clusters
            
        except Exception as e:
            self.logger.warning(f"Hierarchical clustering failed: {e}")
        
        # Method 2: DBSCAN clustering (fallback)
        if HAS_SKLEARN and self.use_clustering:
            try:
                # Adaptive epsilon based on image size
                eps = max(10, min(50, np.sqrt(image.shape[0] * image.shape[1]) / 20))
                min_samples = max(2, len(dot_positions) // 10)
                
                dbscan = DBSCAN(eps=eps, min_samples=min_samples)
                cluster_labels = dbscan.fit_predict(dot_positions)
                
                # Group dots by cluster (ignore noise points labeled as -1)
                clusters = []
                unique_labels = set(cluster_labels) - {-1}
                
                for label in unique_labels:
                    cluster_dots = [i for i, l in enumerate(cluster_labels) if l == label]
                    if len(cluster_dots) >= 2:
                        clusters.append(cluster_dots)
                
                if clusters:
                    self.logger.debug(f"DBSCAN clustering found {len(clusters)} tissue clusters")
                    return clusters
                    
            except Exception as e:
                self.logger.warning(f"DBSCAN clustering failed: {e}")
        
        # Method 3: Distance-based grouping (final fallback)
        return self._simple_distance_clustering(dot_positions, image)
    
    def _simple_distance_clustering(self, dot_positions: np.ndarray, image: np.ndarray) -> List[List[int]]:
        """
        Simple distance-based clustering as a fallback method.
        """
        if len(dot_positions) < 2:
            return [list(range(len(dot_positions)))]
        
        # Use simple distance threshold
        distance_threshold = max(20, min(100, np.sqrt(image.shape[0] * image.shape[1]) / 15))
        
        clusters = []
        unassigned = list(range(len(dot_positions)))
        
        while unassigned:
            # Start new cluster with first unassigned point
            current_cluster = [unassigned.pop(0)]
            
            # Find all points within distance threshold
            changed = True
            while changed:
                changed = False
                for i in list(unassigned):
                    # Check distance to any point in current cluster
                    min_dist = min([
                        np.linalg.norm(dot_positions[i] - dot_positions[j])
                        for j in current_cluster
                    ])
                    
                    if min_dist <= distance_threshold:
                        current_cluster.append(i)
                        unassigned.remove(i)
                        changed = True
            
            if len(current_cluster) >= 2:  # Only keep clusters with multiple dots
                clusters.append(current_cluster)
        
        self.logger.debug(f"Distance-based clustering found {len(clusters)} tissue clusters")
        return clusters
    
    def _create_regions_from_clusters(self, image: np.ndarray, clusters: List[List[int]], dot_positions: np.ndarray) -> List[Dict[str, Any]]:
        """
        Create tissue region descriptors from dot clusters.
        """
        regions = []
        
        for i, cluster_indices in enumerate(clusters):
            if not cluster_indices:
                continue
            
            cluster_dots = dot_positions[cluster_indices]
            
            # Calculate cluster properties
            centroid = np.mean(cluster_dots, axis=0)
            
            # Create bounding box around cluster
            min_row, min_col = np.min(cluster_dots, axis=0)
            max_row, max_col = np.max(cluster_dots, axis=0)
            
            # Expand bounding box slightly
            padding = 10
            bbox = (
                max(0, int(min_row - padding)),
                max(0, int(min_col - padding)),
                min(image.shape[0], int(max_row + padding)),
                min(image.shape[1], int(max_col + padding))
            )
            
            # Extract region from image
            region_image = image[bbox[0]:bbox[2], bbox[1]:bbox[3]]
            
            # Estimate area based on cluster size and local image intensity
            estimated_area = len(cluster_indices) * 10  # Rough estimate
            
            region_info = {
                'cluster_id': i,
                'centroid': centroid,
                'bbox': bbox,
                'area': estimated_area,
                'dot_count': len(cluster_indices),
                'dot_positions': cluster_dots,
                'region_image': region_image
            }
            
            regions.append(region_info)
        
        return regions
    
    def _multi_threshold_segmentation(self, image: np.ndarray, num_thresholds: int = 3) -> np.ndarray:
        """
        Apply multi-level thresholding for tissue separation.
        
        Args:
            image: Input grayscale image
            num_thresholds: Number of threshold levels
            
        Returns:
            Multi-level segmented image
        """
        try:
            # Apply Gaussian filter to reduce noise
            filtered = filters.gaussian(image, sigma=1.0)
            
            # Use Otsu's method with multiple thresholds
            thresholds = filters.threshold_multiotsu(filtered, classes=num_thresholds + 1)
            
            # Create multi-level segmentation
            segmented = np.digitize(filtered, thresholds)
            
            return segmented.astype(np.uint8)
            
        except Exception as e:
            self.logger.error(f"Multi-threshold segmentation failed: {e}")
            # Fallback to simple binary threshold
            threshold = filters.threshold_otsu(image)
            return (image > threshold).astype(np.uint8)
    
    def _watershed_segmentation(self, image: np.ndarray, markers: Optional[np.ndarray] = None) -> np.ndarray:
        """
        Apply watershed segmentation for tissue separation.
        
        Args:
            image: Input grayscale image
            markers: Optional marker image for seeded watershed
            
        Returns:
            Watershed segmented image
        """
        try:
            # Compute gradient magnitude
            gradient = filters.sobel(image)
            
            if markers is None:
                # Auto-generate markers using local maxima
                local_maxima = feature.peak_local_max(
                    image,
                    min_distance=10,
                    threshold_abs=np.percentile(image, 70),
                    exclude_border=True,
                    indices=False
                )
                markers = measure.label(local_maxima)
            
            # Apply watershed
            labels = segmentation.watershed(gradient, markers, mask=image > 0)
            
            return labels.astype(np.uint8)
            
        except Exception as e:
            self.logger.error(f"Watershed segmentation failed: {e}")
            # Fallback to thresholding
            threshold = filters.threshold_otsu(image)
            return (image > threshold).astype(np.uint8)
    
    def _validate_segmentation(self, segmented: np.ndarray, original: np.ndarray) -> Dict[str, float]:
        """
        Validate segmentation quality with various metrics.
        
        Args:
            segmented: Segmented image
            original: Original image
            
        Returns:
            Dictionary of validation metrics
        """
        metrics = {}
        
        try:
            # Coverage metrics
            total_pixels = original.size
            segmented_pixels = np.sum(segmented > 0)
            metrics['coverage_ratio'] = segmented_pixels / total_pixels
            
            # Region properties
            labeled = measure.label(segmented)
            regions = measure.regionprops(labeled)
            
            if regions:
                areas = [region.area for region in regions]
                metrics['num_regions'] = len(regions)
                metrics['mean_region_area'] = np.mean(areas)
                metrics['std_region_area'] = np.std(areas)
                
                # Compactness (circularity) metrics
                compactness = []
                for region in regions:
                    if region.area > 10:  # Skip very small regions
                        perimeter = region.perimeter
                        if perimeter > 0:
                            compactness.append((4 * np.pi * region.area) / (perimeter ** 2))
                
                if compactness:
                    metrics['mean_compactness'] = np.mean(compactness)
                    metrics['std_compactness'] = np.std(compactness)
            
            # Intensity-based metrics
            foreground_intensity = original[segmented > 0]
            background_intensity = original[segmented == 0]
            
            if len(foreground_intensity) > 0 and len(background_intensity) > 0:
                metrics['foreground_mean'] = np.mean(foreground_intensity)
                metrics['background_mean'] = np.mean(background_intensity)
                metrics['contrast_ratio'] = (
                    np.mean(foreground_intensity) / np.mean(background_intensity)
                    if np.mean(background_intensity) > 0 else np.inf
                )
                
        except Exception as e:
            self.logger.error(f"Segmentation validation failed: {e}")
            metrics['error'] = str(e)
        
        return metrics